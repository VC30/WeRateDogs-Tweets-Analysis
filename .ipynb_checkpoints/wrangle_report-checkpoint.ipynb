{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We Rate Dogs Data Wrangling Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA COLLECTION\n",
    "\n",
    "I started this project by the gathering the three relevant datasets needed to complete the project. I started by manually downloading the first dataset which is the 'twitter-archive-enhanced.csv'. I then read this dataset into the pandas dataframe and viewed the head of the dataset. Secondly, I created a folder named 'tweeted_images' through the jupyter notebook. Then through the given url, I downloaded the tsv file 'image-predictions.tsv' programatically. After which I read the dataset into the pandas dataframe and viewed the head of the dataset. Unfortunately, I could not get the last dataset from twitter's API so I downloaded it directly from the link provided by Udacity. \n",
    "\n",
    "ASSESSING AND CLEANING THE DATA \n",
    "\n",
    "I did basic Exploratory Data Analysis on the three datasets. Through this analysis, I was able to detect some issues with the dataset which include:\n",
    "\n",
    "QUALITY ISSUES:\n",
    "- adjust upper case in text column\n",
    "- items in text column contain url and symbols only\n",
    "- incosistency in the usage of - and _ in p1 column\n",
    "- incosistency in the usage of - and _ in p2 column\n",
    "- incosistency in the usage of - and _ in p3 column\n",
    "- eliminate rows containing retweet through text column\n",
    "- adjust the source column for readability\n",
    "- adjust duplicates items in name column (a)\n",
    "- missing values in name column      \n",
    "\n",
    "TIDINESS ISSUES\n",
    "- contains redudant columns: retweeted_status_id,retweeted_status_user_id,retweeted_status_timestamp, in_reply_to_status_id,in_reply_to_user_id\n",
    "- rename json id column to tweet_id\n",
    "\n",
    "I created a duplicate copy for each dataset and all of the above issues were corrected during the cleaning phase of the project using the duplicated copies. After the cleaning process, the three datasets were merged together to form a master dataset and saved as a csv file called 'twitter_archive_master.csv'. Then the csv file was analyzed and visualized to derive meaningful insights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
